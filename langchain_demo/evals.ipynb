{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "\n",
    "pdagent_type = 'auto' #one of: auto, manual\n",
    "llm_type = 'gpt-4o' #one of: gpt-3.5-turbo-0613, gpt-3.5-turbo-0125, gpt-3.5-turbo, gpt-4o\n",
    "initialization_params = {} #eg json version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/snc/opt/anaconda3/envs/giss/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import chromadb\n",
    "import gradio as gr\n",
    "\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    import key\n",
    "    key.init()\n",
    "    assert os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 6985 rows corresponding to old-version datasets\n",
      "skipping CMIP6_coordinate.json due to formatting issue\n",
      "skipping CMIP6_input_example.json due to formatting issue\n",
      "skipping CMIP6_CV.json due to formatting issue\n",
      "skipping CMIP6_formula_terms.json due to formatting issue\n"
     ]
    }
   ],
   "source": [
    "path = './model_experiment_fields_ScenarioMIP_CMIP_filename_dates.csv'\n",
    "df = pd.read_csv(path)\n",
    "df['collection'] = 'giss_cmip6'\n",
    "df = df[['collection', 'MIP', 'model', 'experiment', 'variant', 'tableID', 'variable', 'grid', 'version', 'start_YM', 'end_YM', 'filename']]\n",
    "df.columns = ['collection', 'MIP', 'model', 'experiment', 'variant', 'temporal resolution', 'variable', 'grid', 'version', 'start year', 'end year', 'filename']\n",
    "df = df.astype(str)\n",
    "\n",
    "def url(x):\n",
    "    cols = '/'.join(x)\n",
    "    return 'portal.nccs.nasa.gov/datashare/' + cols\n",
    "df['URL'] = df.apply(lambda x: url(x), axis=1)\n",
    "\n",
    "df['start year'] = df['start year'].apply(lambda x: x[:4]) #+'-'+x[4:])\n",
    "df['end year'] = df['end year'].apply(lambda x: x[:4]) #+'-'+x[4:])\n",
    "\n",
    "oldn = df.shape[0]\n",
    "df = df.sort_values(df.columns.to_list(), ascending=True).drop_duplicates(\n",
    "    subset=set(df.columns.to_list())-set(['version', 'filename', 'URL']),\n",
    "    ignore_index=True, keep='last')\n",
    "print('removed', oldn-df.shape[0], 'rows corresponding to old-version datasets')\n",
    "\n",
    "path = '../../cmip6-cmor-tables/Tables'\n",
    "jdfs = []\n",
    "for fname in os.listdir(path):\n",
    "    with open(os.path.join(path, fname)) as j:\n",
    "        d = json.load(j)\n",
    "    \n",
    "    try: \n",
    "        jdf = pd.DataFrame.from_dict(d['variable_entry'], orient='index')\n",
    "    except:\n",
    "        print('skipping', fname, 'due to formatting issue')\n",
    "        continue    \n",
    "    \n",
    "    jdf['temporal resolution'] = fname[len('CMIP6_'):-len('.json')]\n",
    "    jdfs.append(jdf)\n",
    "    \n",
    "varsdf = pd.concat(jdfs)\n",
    "varsdf.rename(columns={'out_name': 'variable'}, inplace=True)\n",
    "varsdf = varsdf.drop_duplicates(subset=['variable', 'temporal resolution'])\n",
    "\n",
    "dfm = df.merge(varsdf, how='left')\n",
    "dfm.drop_duplicates(subset=set(dfm.columns.to_list())-set(['dimensions'])).shape\n",
    "dfmsub = dfm.drop(['temporal resolution', 'grid', 'version', 'type', 'positive', 'valid_min', 'valid_max', \n",
    "        'ok_min_mean_abs', 'ok_max_mean_abs', 'flag_values', 'flag_meanings'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"summarize the user's request in a few key words without punctuation. \"\n",
    "    \"Do NOT attempt to answer the user's request. \"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=llm_type, temperature=0)\n",
    "chain_standalone = contextualize_q_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/snc/opt/anaconda3/envs/giss/lib/python3.11/site-packages/langchain_experimental/agents/agent_toolkits/pandas/base.py:282: UserWarning: Received additional kwargs {'handle_parsing_errors': \"You you believe that the data doesn't contain the information you are looking for, please try rephrasing your question.\", 'response_format': {'type': 'json_object'}} which are no longer supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if pdagent_type == 'auto':\n",
    "    class create_pd_agent_that_returns_just_dataframe:\n",
    "        def __init__(self, model, df):\n",
    "            system = f\"\"\"\n",
    "                You are a climate scientist with a pandas dataframe `df` that lists and describes all datasets \n",
    "                within CMIP6. Here is the output of `df.head().to_markdown:` \\\n",
    "                {df.head().to_markdown()} \\\n",
    "                Given a colleague's query, EXECUTE Python code to find ROWs of `df` corresponding \n",
    "                to CMIP6 datasets *similar* to the query (not necessarily an exact match!). \\\n",
    "                    Return ONLY the entire rows of `df` and nothing else. EXECUTE the code yourself!!\n",
    "                    Do it yourself!!\"\"\"\n",
    "            self.pdagent = create_pandas_dataframe_agent(\n",
    "                model,\n",
    "                dfmsub,\n",
    "                prefix=system,\n",
    "                verbose=True,\n",
    "                agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "                allow_dangerous_code=True,\n",
    "                handle_parsing_errors=\"You you believe that the data doesn't contain the information you are looking for, please try rephrasing your question.\",\n",
    "                return_intermediate_steps=True,\n",
    "                response_format={ \"type\": \"json_object\" },\n",
    "            )\n",
    "        def invoke(self, query):\n",
    "            # return self.pdagent.invoke(query)\n",
    "            try:\n",
    "                result = self.pdagent.invoke(query)\n",
    "                return result['intermediate_steps'][0][1]\n",
    "            except:\n",
    "                return pd.DataFrame([])\n",
    "            \n",
    "    model = ChatOpenAI(temperature=0, model=llm_type)\n",
    "    pdagent = create_pd_agent_that_returns_just_dataframe(model, dfmsub)\n",
    "    \n",
    "elif pdagent_type == 'manual':\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-4o\", )\n",
    "    tool = PythonAstREPLTool(locals={\"df\": dfmsub})\n",
    "    llm_with_tools = llm.bind_tools([tool], tool_choice=tool.name)\n",
    "    parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)\n",
    "\n",
    "    system = f\"\"\"\n",
    "    You are a climate scientist with a pandas dataframe `df` that lists and describes all datasets \n",
    "    within CMIP6. Here is the output of `df.head().to_markdown:` \\\n",
    "    {dfmsub.head().to_markdown()} \\\n",
    "    Given a colleague's query, find ROWs of `df` corresponding \n",
    "    to CMIP6 datasets *similar* to the query (not necessarily an exact match!). \\\n",
    "        Return ONLY the entire rows of `df` and nothing else. EXECUTE the code yourself!!\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "    pdagent = prompt | llm_with_tools | parser | tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>src</th>\n",
       "      <th>query</th>\n",
       "      <th>variable</th>\n",
       "      <th>frequency</th>\n",
       "      <th>start year</th>\n",
       "      <th>end year</th>\n",
       "      <th>MIP</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>What are some datasets relevant to extreme wea...</td>\n",
       "      <td>pr, ua, etc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Plot the 10, 20, 50, and 100 yr return period ...</td>\n",
       "      <td>pr</td>\n",
       "      <td>day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>historical</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Show me all the times where Ames Iowa has more...</td>\n",
       "      <td>tas</td>\n",
       "      <td>day</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>CMIP</td>\n",
       "      <td>historical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Show me the average annual number of days per ...</td>\n",
       "      <td>tasmax</td>\n",
       "      <td>day</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>ssp&lt;NNN&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>You just showed me average annual number of da...</td>\n",
       "      <td>tasmax</td>\n",
       "      <td>day</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>ssp&lt;NNN&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotator src                                              query  \\\n",
       "0     Sonia  Us  What are some datasets relevant to extreme wea...   \n",
       "1     Sonia  Us  Plot the 10, 20, 50, and 100 yr return period ...   \n",
       "2     Sonia  Us  Show me all the times where Ames Iowa has more...   \n",
       "3     Sonia  Us  Show me the average annual number of days per ...   \n",
       "4     Sonia  Us  You just showed me average annual number of da...   \n",
       "\n",
       "      variable frequency  start year  end year          MIP  experiment  \n",
       "0  pr, ua, etc       NaN         NaN       NaN          NaN         NaN  \n",
       "1           pr       day         NaN       NaN   historical         NaN  \n",
       "2          tas       day      1980.0    2014.0         CMIP  historical  \n",
       "3       tasmax       day      2050.0    2070.0  ScenarioMIP    ssp<NNN>  \n",
       "4       tasmax       day      2050.0    2070.0  ScenarioMIP    ssp<NNN>  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.read_excel('evals.xlsx')\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dictsets(r):\n",
    "    for k,v in r.to_dict().items(): \n",
    "        if type(v)==str and ',' in v and k != 'query':\n",
    "            r[k] = set(v.split(', '))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets for extreme weather\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Return period plot for maximum daily rainfall\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo create a return period plot for maximum daily rainfall, you typically need a time series of daily rainfall data. The return period plot (or return level plot) is used in extreme value analysis to estimate the probability of extreme events, such as heavy rainfall.\n",
      "\n",
      "Here is a step-by-step guide to create a return period plot for maximum daily rainfall using Python:\n",
      "\n",
      "1. **Load the data**: Ensure you have a time series of daily rainfall data.\n",
      "2. **Fit an extreme value distribution**: Use the Generalized Extreme Value (GEV) distribution or another appropriate distribution.\n",
      "3. **Calculate return levels**: Estimate the return levels for different return periods.\n",
      "4. **Plot the return period plot**.\n",
      "\n",
      "Below is an example code snippet to achieve this using Python and libraries like `pandas`, `numpy`, `scipy`, and `matplotlib`:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import genextreme as gev\n",
      "\n",
      "# Load your daily rainfall data into a pandas DataFrame\n",
      "# For example, let's assume you have a CSV file with a 'date' and 'rainfall' column\n",
      "# df = pd.read_csv('daily_rainfall.csv', parse_dates=['date'])\n",
      "\n",
      "# Generate some synthetic daily rainfall data for demonstration\n",
      "np.random.seed(42)\n",
      "dates = pd.date_range(start='2000-01-01', end='2020-12-31', freq='D')\n",
      "rainfall = np.random.gamma(shape=2.0, scale=10.0, size=len(dates))\n",
      "df = pd.DataFrame({'date': dates, 'rainfall': rainfall})\n",
      "\n",
      "# Extract the maximum daily rainfall for each year\n",
      "df['year'] = df['date'].dt.year\n",
      "annual_max = df.groupby('year')['rainfall'].max()\n",
      "\n",
      "# Fit the GEV distribution to the annual maximum data\n",
      "params = gev.fit(annual_max)\n",
      "\n",
      "# Define return periods\n",
      "return_periods = np.array([2, 5, 10, 20, 50, 100])\n",
      "\n",
      "# Calculate return levels\n",
      "return_levels = gev.ppf(1 - 1/return_periods, *params)\n",
      "\n",
      "# Plot the return period plot\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.plot(return_periods, return_levels, marker='o', linestyle='-')\n",
      "plt.xscale('log')\n",
      "plt.xlabel('Return Period (years)')\n",
      "plt.ylabel('Return Level (mm)')\n",
      "plt.title('Return Period Plot for Maximum Daily Rainfall')\n",
      "plt.grid(True)\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Load the data**: Replace the synthetic data generation with your actual data loading code.\n",
      "2. **Extract annual maxima**: Group the data by year and extract the maximum daily rainfall for each year.\n",
      "3. **Fit the GEV distribution**: Use the `scipy.stats.genextreme` function to fit the GEV distribution to the annual maxima.\n",
      "4. **Calculate return levels**: Use the percent point function (inverse of the cumulative distribution function) to calculate the return levels for specified return periods.\n",
      "5. **Plot the return period plot**: Plot the return levels against the return periods on a logarithmic scale.\n",
      "\n",
      "This code will generate a return period plot for maximum daily rainfall, which can help in understanding the probability of extreme rainfall events.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Ames Iowa frost days historical simulation 1980-2014\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Assuming df is already defined and loaded with the CMIP6 datasets\\nquery = 'Ames Iowa frost days historical simulation 1980-2014'\\n\\n# Filter the dataframe for relevant rows\\nfiltered_df = df[(df['experiment'].str.contains('historical', case=False)) &\\n                 (df['start year'] <= 1980) & (df['end year'] >= 2014) &\\n                 (df['long_name'].str.contains('frost', case=False))]\\n\\nfiltered_df\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mEmpty DataFrame\n",
      "Columns: [collection, MIP, model, experiment, variant, variable, start year, end year, filename, URL, frequency, modeling_realm, standard_name, units, cell_methods, cell_measures, long_name, comment, dimensions]\n",
      "Index: []\u001b[0m\u001b[32;1m\u001b[1;3mIt appears that there are no datasets in the provided CMIP6 dataframe that match the query for \"Ames Iowa frost days historical simulation 1980-2014\". \n",
      "\n",
      "You might want to check if there are any datasets related to frost days or similar variables under different experiments or time periods. If you have more specific details or alternative keywords, please provide them, and I can refine the search accordingly.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "average annual days exceeding 98°F 2050-2070\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "average annual days exceeding 102°F\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "average annual rainfall days 1980-2014 uncoupled run\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "future suitable places for wheat cultivation\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Sample data based on the provided dataframe structure\\ndata = {\\n    'collection': ['giss_cmip6', 'giss_cmip6', 'giss_cmip6', 'giss_cmip6', 'giss_cmip6'],\\n    'MIP': ['CMIP', 'CMIP', 'CMIP', 'CMIP', 'CMIP'],\\n    'model': ['GISS-E2-1-G', 'GISS-E2-1-G', 'GISS-E2-1-G', 'GISS-E2-1-G', 'GISS-E2-1-G'],\\n    'experiment': ['1pctCO2', '1pctCO2', '1pctCO2', '1pctCO2', '1pctCO2'],\\n    'variant': ['r101i1p1f1', 'r101i1p1f1', 'r101i1p1f1', 'r101i1p1f1', 'r101i1p1f1'],\\n    'variable': ['bldep', 'bldep', 'bldep', 'bldep', 'cltc'],\\n    'start year': [1850, 1901, 1951, 2001, 1850],\\n    'end year': [1900, 1950, 2000, 2019, 1900],\\n    'filename': [\\n        'bldep_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_185001-190012.nc',\\n        'bldep_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_190101-195012.nc',\\n        'bldep_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_195101-200012.nc',\\n        'bldep_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_200101-201912.nc',\\n        'cltc_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_185001-190012.nc'\\n    ],\\n    'URL': [\\n        'portal.nccs.nasa.gov/datashare/giss_cmip6/CMIP/GISS-E2-1-G/1pctCO2/r101i1p1f1/AERmon/bldep/gn/v20190815/185001/190012/bldep_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_185001-190012.nc',\\n        'portal.nccs.nasa.gov/datashare/giss_cmip6/CMIP/GISS-E2-1-G/1pctCO2/r101i1p1f1/AERmon/bldep/gn/v20190815/190101/195012/bldep_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_190101-195012.nc',\\n        'portal.nccs.nasa.gov/datashare/giss_cmip6/CMIP/GISS-E2-1-G/1pctCO2/r101i1p1f1/AERmon/bldep/gn/v20190815/195101/200012/bldep_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_195101-200012.nc',\\n        'portal.nccs.nasa.gov/datashare/giss_cmip6/CMIP/GISS-E2-1-G/1pctCO2/r101i1p1f1/AERmon/bldep/gn/v20190815/200101/201912/bldep_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_200101-201912.nc',\\n        'portal.nccs.nasa.gov/datashare/giss_cmip6/CMIP/GISS-E2-1-G/1pctCO2/r101i1p1f1/AERmon/cltc/gn/v20190815/185001/190012/cltc_AERmon_GISS-E2-1-G_1pctCO2_r101i1p1f1_gn_185001-190012.nc'\\n    ],\\n    'frequency': ['mon', 'mon', 'mon', 'mon', 'mon'],\\n    'modeling_realm': ['aerosol', 'aerosol', 'aerosol', 'aerosol', 'aerosol'],\\n    'standard_name': [\\n        'atmosphere_boundary_layer_thickness',\\n        'atmosphere_boundary_layer_thickness',\\n        'atmosphere_boundary_layer_thickness',\\n        'atmosphere_boundary_layer_thickness',\\n        'convective_cloud_area_fraction'\\n    ],\\n    'units': ['m', 'm', 'm', 'm', '%'],\\n    'cell_methods': ['area: time: mean', 'area: time: mean', 'area: time: mean', 'area: time: mean', 'area: time: mean'],\\n    'cell_measures': ['area: areacella', 'area: areacella', 'area: areacella', 'area: areacella', 'area: areacella'],\\n    'long_name': [\\n        'Boundary Layer Depth',\\n        'Boundary Layer Depth',\\n        'Boundary Layer Depth',\\n        'Boundary Layer Depth',\\n        'Convective Cloud Cover Percentage'\\n    ],\\n    'comment': [\\n        'Boundary layer depth',\\n        'Boundary layer depth',\\n        'Boundary layer depth',\\n        'Boundary layer depth',\\n        'Convective cloud area fraction (reported as a percentage) for the whole atmospheric column, as seen from the surface or the top of the atmosphere. Includes only convective cloud.'\\n    ],\\n    'dimensions': ['longitude latitude time', 'longitude latitude time', 'longitude latitude time', 'longitude latitude time', 'longitude latitude time']\\n}\\n\\ndf = pd.DataFrame(data)\\n\\n# Filter datasets related to temperature and precipitation\\nrelevant_variables = ['tas', 'pr']\\nfiltered_df = df[df['variable'].isin(relevant_variables)]\\nfiltered_df\"}`\n",
      "responded: To determine future suitable places for wheat cultivation, we need to consider various climate variables such as temperature, precipitation, soil moisture, and other relevant factors. The CMIP6 datasets can provide projections of these variables under different climate scenarios.\n",
      "\n",
      "Let's start by identifying relevant datasets from the CMIP6 collection that include variables related to temperature and precipitation, which are critical for wheat cultivation.\n",
      "\n",
      "I'll execute Python code to find rows in the dataframe `df` that correspond to datasets with variables related to temperature and precipitation.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mEmpty DataFrame\n",
      "Columns: [collection, MIP, model, experiment, variant, variable, start year, end year, filename, URL, frequency, modeling_realm, standard_name, units, cell_methods, cell_measures, long_name, comment, dimensions]\n",
      "Index: []\u001b[0m\u001b[32;1m\u001b[1;3mIt appears that the sample data provided does not contain variables directly related to temperature (`tas`) or precipitation (`pr`). To proceed, we would typically need to access a more comprehensive dataset that includes these variables.\n",
      "\n",
      "However, based on the structure of the dataframe, you can filter for relevant variables in a similar manner if you have access to the full CMIP6 dataset. Here is an example of how you would filter for temperature and precipitation datasets:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Assuming df is your dataframe containing CMIP6 datasets\n",
      "relevant_variables = ['tas', 'pr']  # 'tas' for temperature, 'pr' for precipitation\n",
      "filtered_df = df[df['variable'].isin(relevant_variables)]\n",
      "\n",
      "print(filtered_df)\n",
      "```\n",
      "\n",
      "This code will filter the dataframe to include only rows where the variable is either temperature or precipitation. You can then analyze these datasets to determine future suitable places for wheat cultivation based on projected climate conditions.\n",
      "\n",
      "If you have access to the full dataset and need further assistance with the analysis, please provide the relevant data or let me know how I can assist you further.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "future drought simulation northeastern china southeastern US\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Assuming df is already defined and contains the CMIP6 datasets\\n\\n# Query for future drought simulation in northeastern China and southeastern US\\nquery = df[(df['long_name'].str.contains('drought', case=False, na=False)) & \\n            (df['comment'].str.contains('northeastern China', case=False, na=False) | \\n             df['comment'].str.contains('southeastern US', case=False, na=False))]\\n\\nquery\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mEmpty DataFrame\n",
      "Columns: [collection, MIP, model, experiment, variant, variable, start year, end year, filename, URL, frequency, modeling_realm, standard_name, units, cell_methods, cell_measures, long_name, comment, dimensions]\n",
      "Index: []\u001b[0m\u001b[32;1m\u001b[1;3mIt appears that there are no datasets in the provided CMIP6 dataframe that specifically mention \"drought\" in the `long_name` or \"northeastern China\" or \"southeastern US\" in the `comment`.\n",
      "\n",
      "You might want to broaden your search criteria or check for related variables and comments that could be indicative of drought conditions, such as precipitation, soil moisture, or temperature anomalies. If you have any other specific keywords or criteria, please let me know!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "average SPEI SSP585 scenario 2080-2100\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "outs = []\n",
    "for i, r in queries.iterrows():\n",
    "    r = to_dictsets(r)\n",
    "    conversation = {'input': r['query'], 'chat_history': []}\n",
    "    standalone = chain_standalone.invoke(conversation)\n",
    "    print(standalone)\n",
    "    # model = ChatOpenAI(temperature=0, model=llm_type)\n",
    "    # pdagent = create_pd_agent_that_returns_just_dataframe(model, dfmsub)\n",
    "    # out = pdagent.invoke(standalone+'?')\n",
    "    outs.append(pdagent.invoke(standalone+'?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "non_score_cols = set(['annotator', 'src', 'query'])\n",
    "pts= 0\n",
    "valids = 0\n",
    "for i in range(len(outs)):\n",
    "    out = outs[i]\n",
    "    r = queries.iloc[i]\n",
    "    if type(out) != pd.core.frame.DataFrame or len(out) == 0:\n",
    "        continue\n",
    "    \n",
    "    valids += 1\n",
    "    for c in r.index: # get cols where correct response is defined\n",
    "        if c in non_score_cols:\n",
    "            continue\n",
    "        \n",
    "        # print(c, pts, type(r[c]))\n",
    "        if c == 'start year':\n",
    "            pts += sum(out[c].astype(float) <= r[c])/len(out)\n",
    "        elif c == 'end year':\n",
    "            pts += sum(r[c] <= out[c].astype(float))/len(out)\n",
    "        elif r.isna()[c] or (type(r[c])==str and 'etc' in r[c]):\n",
    "            # scoring a string with NaN/etc, count all as correct\n",
    "            pts += 1 # len(out)\n",
    "        else:\n",
    "            if type(r[c])=='str' and ',' in r[c]:\n",
    "                # scoring a string with limited set correct answers\n",
    "                vals = set(r[c].split(', '))\n",
    "            else:\n",
    "                # scoring a string with one correct answer\n",
    "                vals = set([r[c]])\n",
    "            pts += sum(out[c].isin(vals))/len(out)\n",
    "        \n",
    "        # print(c, vals)\n",
    "        # print(sum(out[c].isin(vals)))\n",
    "# pts = pts/len(out)\n",
    "print(valids, pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>src</th>\n",
       "      <th>query</th>\n",
       "      <th>variable</th>\n",
       "      <th>frequency</th>\n",
       "      <th>start year</th>\n",
       "      <th>end year</th>\n",
       "      <th>MIP</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>What are some datasets relevant to extreme wea...</td>\n",
       "      <td>pr, ua, etc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Plot the 10, 20, 50, and 100 yr return period ...</td>\n",
       "      <td>pr</td>\n",
       "      <td>day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>historical</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Show me all the times where Ames Iowa has more...</td>\n",
       "      <td>tas</td>\n",
       "      <td>day</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>CMIP</td>\n",
       "      <td>historical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Show me the average annual number of days per ...</td>\n",
       "      <td>tasmax</td>\n",
       "      <td>day</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>ssp&lt;NNN&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>You just showed me average annual number of da...</td>\n",
       "      <td>tasmax</td>\n",
       "      <td>day</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>ssp&lt;NNN&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Get the average annual number of days rainfall...</td>\n",
       "      <td>pr</td>\n",
       "      <td>day</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>CMIP</td>\n",
       "      <td>amip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Show me in the future, all the suitable places...</td>\n",
       "      <td>clt, pr, etc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>ssp&lt;NNN&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Show me a future simulation where there is a d...</td>\n",
       "      <td>pr, tas, etc</td>\n",
       "      <td>mon</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>ssp&lt;NNN&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sonia</td>\n",
       "      <td>Us</td>\n",
       "      <td>Tell me the average SPEI under SSP585 scenario...</td>\n",
       "      <td>tas, pr</td>\n",
       "      <td>mon</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>ssp585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotator src                                              query  \\\n",
       "0     Sonia  Us  What are some datasets relevant to extreme wea...   \n",
       "1     Sonia  Us  Plot the 10, 20, 50, and 100 yr return period ...   \n",
       "2     Sonia  Us  Show me all the times where Ames Iowa has more...   \n",
       "3     Sonia  Us  Show me the average annual number of days per ...   \n",
       "4     Sonia  Us  You just showed me average annual number of da...   \n",
       "5     Sonia  Us  Get the average annual number of days rainfall...   \n",
       "6     Sonia  Us  Show me in the future, all the suitable places...   \n",
       "7     Sonia  Us  Show me a future simulation where there is a d...   \n",
       "8     Sonia  Us  Tell me the average SPEI under SSP585 scenario...   \n",
       "\n",
       "       variable frequency  start year  end year          MIP  experiment  \n",
       "0   pr, ua, etc       NaN         NaN       NaN          NaN         NaN  \n",
       "1            pr       day         NaN       NaN   historical         NaN  \n",
       "2           tas       day      1980.0    2014.0         CMIP  historical  \n",
       "3        tasmax       day      2050.0    2070.0  ScenarioMIP    ssp<NNN>  \n",
       "4        tasmax       day      2050.0    2070.0  ScenarioMIP    ssp<NNN>  \n",
       "5            pr       day      1980.0    2014.0         CMIP        amip  \n",
       "6  clt, pr, etc       NaN      2015.0       NaN  ScenarioMIP    ssp<NNN>  \n",
       "7  pr, tas, etc       mon      2015.0       NaN  ScenarioMIP    ssp<NNN>  \n",
       "8       tas, pr       mon      2080.0    2100.0  ScenarioMIP      ssp585  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "giss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
