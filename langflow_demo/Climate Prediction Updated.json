{"id":"043b5ecb-c0a6-4afc-ba2c-fa62d787d04c","data":{"nodes":[{"id":"OpenAIEmbeddings-oxAcv","type":"genericNode","position":{"x":1544.7020298104862,"y":601.2188466539114},"data":{"id":"OpenAIEmbeddings-oxAcv","node":{"base_classes":["Embeddings"],"beta":false,"custom_fields":{"allowed_special":null,"chunk_size":null,"client":null,"default_headers":null,"default_query":null,"deployment":null,"disallowed_special":null,"embedding_ctx_length":null,"max_retries":null,"model":null,"model_kwargs":null,"openai_api_base":null,"openai_api_key":null,"openai_api_type":null,"openai_api_version":null,"openai_organization":null,"openai_proxy":null,"request_timeout":null,"show_progress_bar":null,"skip_empty":null,"tiktoken_enable":null,"tiktoken_model_name":null},"description":"Generate embeddings using OpenAI models.","display_name":"OpenAI Embeddings","documentation":"","field_formatters":{},"field_order":[],"frozen":false,"output_types":["Embeddings"],"template":{"_type":"CustomComponent","allowed_special":{"advanced":true,"display_name":"Allowed Special","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"allowed_special","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":[]},"chunk_size":{"advanced":true,"display_name":"Chunk Size","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"chunk_size","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Dict, List, Optional\n\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, NestedDict\n\n\nclass OpenAIEmbeddingsComponent(CustomComponent):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n\n    def build_config(self):\n        return {\n            \"allowed_special\": {\n                \"display_name\": \"Allowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"default_headers\": {\n                \"display_name\": \"Default Headers\",\n                \"advanced\": True,\n                \"field_type\": \"dict\",\n            },\n            \"default_query\": {\n                \"display_name\": \"Default Query\",\n                \"advanced\": True,\n                \"field_type\": \"NestedDict\",\n            },\n            \"disallowed_special\": {\n                \"display_name\": \"Disallowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"advanced\": True},\n            \"client\": {\"display_name\": \"Client\", \"advanced\": True},\n            \"deployment\": {\"display_name\": \"Deployment\", \"advanced\": True},\n            \"embedding_ctx_length\": {\n                \"display_name\": \"Embedding Context Length\",\n                \"advanced\": True,\n            },\n            \"max_retries\": {\"display_name\": \"Max Retries\", \"advanced\": True},\n            \"model\": {\n                \"display_name\": \"Model\",\n                \"advanced\": False,\n                \"options\": [\n                    \"text-embedding-3-small\",\n                    \"text-embedding-3-large\",\n                    \"text-embedding-ada-002\",\n                ],\n            },\n            \"model_kwargs\": {\"display_name\": \"Model Kwargs\", \"advanced\": True},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"password\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\"display_name\": \"OpenAI API Key\", \"password\": True},\n            \"openai_api_type\": {\n                \"display_name\": \"OpenAI API Type\",\n                \"advanced\": True,\n                \"password\": True,\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"advanced\": True,\n            },\n            \"openai_organization\": {\n                \"display_name\": \"OpenAI Organization\",\n                \"advanced\": True,\n            },\n            \"openai_proxy\": {\"display_name\": \"OpenAI Proxy\", \"advanced\": True},\n            \"request_timeout\": {\"display_name\": \"Request Timeout\", \"advanced\": True},\n            \"show_progress_bar\": {\n                \"display_name\": \"Show Progress Bar\",\n                \"advanced\": True,\n            },\n            \"skip_empty\": {\"display_name\": \"Skip Empty\", \"advanced\": True},\n            \"tiktoken_model_name\": {\n                \"display_name\": \"TikToken Model Name\",\n                \"advanced\": True,\n            },\n            \"tiktoken_enable\": {\"display_name\": \"TikToken Enable\", \"advanced\": True},\n        }\n\n    def build(\n        self,\n        openai_api_key: str,\n        default_headers: Optional[Dict[str, str]] = None,\n        default_query: Optional[NestedDict] = {},\n        allowed_special: List[str] = [],\n        disallowed_special: List[str] = [\"all\"],\n        chunk_size: int = 1000,\n        deployment: str = \"text-embedding-ada-002\",\n        embedding_ctx_length: int = 8191,\n        max_retries: int = 6,\n        model: str = \"text-embedding-ada-002\",\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        openai_api_type: Optional[str] = None,\n        openai_api_version: Optional[str] = None,\n        openai_organization: Optional[str] = None,\n        openai_proxy: Optional[str] = None,\n        request_timeout: Optional[float] = None,\n        show_progress_bar: bool = False,\n        skip_empty: bool = False,\n        tiktoken_enable: bool = True,\n        tiktoken_model_name: Optional[str] = None,\n    ) -> Embeddings:\n        # This is to avoid errors with Vector Stores (e.g Chroma)\n        if disallowed_special == [\"all\"]:\n            disallowed_special = \"all\"  # type: ignore\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        return OpenAIEmbeddings(\n            tiktoken_enabled=tiktoken_enable,\n            default_headers=default_headers,\n            default_query=default_query,\n            allowed_special=set(allowed_special),\n            disallowed_special=\"all\",\n            chunk_size=chunk_size,\n            deployment=deployment,\n            embedding_ctx_length=embedding_ctx_length,\n            max_retries=max_retries,\n            model=model,\n            model_kwargs=model_kwargs,\n            base_url=openai_api_base,\n            api_key=api_key,\n            openai_api_type=openai_api_type,\n            api_version=openai_api_version,\n            organization=openai_organization,\n            openai_proxy=openai_proxy,\n            timeout=request_timeout,\n            show_progress_bar=show_progress_bar,\n            skip_empty=skip_empty,\n            tiktoken_model_name=tiktoken_model_name,\n        )\n"},"default_headers":{"advanced":true,"display_name":"Default Headers","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"default_headers","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"dict"},"default_query":{"advanced":true,"display_name":"Default Query","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"default_query","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"deployment":{"advanced":true,"display_name":"Deployment","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"deployment","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"text-embedding-ada-002"},"disallowed_special":{"advanced":true,"display_name":"Disallowed Special","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"disallowed_special","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":["all"]},"embedding_ctx_length":{"advanced":true,"display_name":"Embedding Context Length","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"embedding_ctx_length","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":8191},"max_retries":{"advanced":true,"display_name":"Max Retries","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"max_retries","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":6},"model":{"advanced":false,"display_name":"Model","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":true,"load_from_db":false,"multiline":false,"name":"model","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"text-embedding-ada-002"},"model_kwargs":{"advanced":true,"display_name":"Model Kwargs","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"model_kwargs","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"openai_api_base":{"advanced":true,"display_name":"OpenAI API Base","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_base","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"openai_api_key":{"advanced":false,"display_name":"OpenAI API Key","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":true,"multiline":false,"name":"openai_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"openai_api_type":{"advanced":true,"display_name":"OpenAI API Type","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_type","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"openai_api_version":{"advanced":true,"display_name":"OpenAI API Version","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_version","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_organization":{"advanced":true,"display_name":"OpenAI Organization","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_organization","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_proxy":{"advanced":true,"display_name":"OpenAI Proxy","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_proxy","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"request_timeout":{"advanced":true,"display_name":"Request Timeout","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"request_timeout","password":false,"placeholder":"","rangeSpec":{"max":1,"min":-1,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"type":"float"},"show_progress_bar":{"advanced":true,"display_name":"Show Progress Bar","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"show_progress_bar","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"skip_empty":{"advanced":true,"display_name":"Skip Empty","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"skip_empty","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"tiktoken_enable":{"advanced":true,"display_name":"TikToken Enable","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"tiktoken_enable","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":true},"tiktoken_model_name":{"advanced":true,"display_name":"TikToken Model Name","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"tiktoken_model_name","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"}}},"type":"OpenAIEmbeddings"},"selected":false,"width":384,"height":383,"positionAbsolute":{"x":1544.7020298104862,"y":601.2188466539114},"dragging":false},{"id":"File-wx5iL","type":"genericNode","position":{"x":1549.3428642815127,"y":1101.46733291842},"data":{"id":"File-wx5iL","node":{"template":{"path":{"type":"file","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx"],"file_path":"043b5ecb-c0a6-4afc-ba2c-fa62d787d04c/data.csv","password":false,"name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pathlib import Path\nfrom typing import Any, Dict\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_record\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nimport pandas as pd\nfrom langchain_community.document_loaders import DataFrameLoader\nfrom langchain_core.documents import Document\n\n\nclass CSVComponent(CustomComponent):\n    icon = \"🦜\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n                \"field_type\": \"file\",\n                \"file_types\": TEXT_FILE_TYPES,\n                \"info\": f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n            },\n        }\n\n    def build(\n        self,\n        path: str,\n        text_col:str = \"text\"\n    ) -> Record:\n        \n        df = pd.read_csv(path)\n        loader = DataFrameLoader(df, page_content_column=text_col)\n        documents = loader.load()\n        records = [Record.from_document(document) for document in documents]\n        self.status = records\n        return records","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"text_col":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"text","fileTypes":[],"file_path":"","password":false,"name":"text_col","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"icon":"🦜","base_classes":["Record"],"display_name":"CSV Loader","documentation":"","custom_fields":{"path":null,"text_col":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"type":"File","display_name":"CSV Loader"},"selected":false,"width":384,"height":371,"dragging":false,"positionAbsolute":{"x":1549.3428642815127,"y":1101.46733291842}},{"id":"ChatOpenAISpecs-gQfib","type":"genericNode","position":{"x":5296.761326526177,"y":1614.4898331125353},"data":{"type":"ChatOpenAISpecs","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseLanguageModel, NestedDict\n\n\nclass ChatOpenAIComponent(CustomComponent):\n    display_name = \"ChatOpenAI\"\n    description = \"`OpenAI` Chat large language models API.\"\n    icon = \"OpenAI\"\n\n    def build_config(self):\n        return {\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"model_name\": {\"display_name\": \"Model Name\", \"advanced\": False, \"options\": MODEL_NAMES},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": False,\n                \"required\": False,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"advanced\": False,\n                \"required\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"required\": False,\n                \"value\": 0.7,\n            },\n        }\n\n    def build(\n        self,\n        max_tokens: Optional[int] = 0,\n        model_kwargs: NestedDict = {},\n        model_name: str = \"gpt-4o\",\n        openai_api_base: Optional[str] = None,\n        openai_api_key: Optional[str] = None,\n        temperature: float = 0.7,\n    ) -> BaseLanguageModel:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        return ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-4o","fileTypes":[],"file_path":"","password":false,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":false,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":""},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"0.1","fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"`OpenAI` Chat large language models API.","icon":"OpenAI","base_classes":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"display_name":"ChatOpenAI","documentation":"","custom_fields":{"max_tokens":null,"model_kwargs":null,"model_name":null,"openai_api_base":null,"openai_api_key":null,"temperature":null},"output_types":["BaseLanguageModel"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOpenAISpecs-gQfib"},"selected":false,"width":384,"height":563,"dragging":false,"positionAbsolute":{"x":5296.761326526177,"y":1614.4898331125353}},{"id":"ChatInput-u9eMa","type":"genericNode","position":{"x":4782.240603811581,"y":1866.9406624454773},"data":{"type":"ChatInput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Text\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        session_id: Optional[str] = None,\n    ) -> Message:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            files=files,\n            session_id=session_id,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"I am interested in air temperature"},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"files":null,"session_id":null},"output_types":["Message"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":false},"id":"ChatInput-u9eMa","description":"Get chat inputs from the Playground.","display_name":"Chat Input"},"selected":false,"width":384,"height":375,"positionAbsolute":{"x":4782.240603811581,"y":1866.9406624454773},"dragging":false},{"id":"CustomComponent-U3ISA","type":"genericNode","position":{"x":5230.7194072664115,"y":2725.479949464532},"data":{"type":"CustomComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains import RetrievalQA\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_core.documents import Document\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langchain_openai import ChatOpenAI\n\n\nclass Component(CustomComponent):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n    \n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"fields\": {\n                \"display_name\": \"Name - Description\",\n            },\n        }\n\n\n\n    def build(self, fields: list[dict]) -> list[Record]:\n        keys = fields.keys()\n        values = fields.values()\n        \n        result =  [Record(name=key, description=value, type=\"string\") for key, value in zip(keys, values)]\n        return result\n        \n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"fields":{"type":"dict","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"fields","display_name":"Name - Description","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":[{"standard_name":"The standard name of the data"},{"units":"The units in which the data is measured"}]},"_type":"CustomComponent"},"description":"Use as a template to create your own component.","icon":"custom_components","base_classes":["Record"],"display_name":"Attribute Info","documentation":"http://docs.langflow.org/components/custom","custom_fields":{"fields":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"CustomComponent-U3ISA","description":"Use as a template to create your own component.","display_name":"Attribute Info","showNode":true},"selected":false,"width":384,"height":331,"positionAbsolute":{"x":5230.7194072664115,"y":2725.479949464532},"dragging":false},{"id":"OpenAIEmbeddings-5EKft","type":"genericNode","position":{"x":3890.5630088192665,"y":2243.5231275702927},"data":{"id":"OpenAIEmbeddings-5EKft","node":{"base_classes":["Embeddings"],"beta":false,"custom_fields":{"allowed_special":null,"chunk_size":null,"client":null,"default_headers":null,"default_query":null,"deployment":null,"disallowed_special":null,"embedding_ctx_length":null,"max_retries":null,"model":null,"model_kwargs":null,"openai_api_base":null,"openai_api_key":null,"openai_api_type":null,"openai_api_version":null,"openai_organization":null,"openai_proxy":null,"request_timeout":null,"show_progress_bar":null,"skip_empty":null,"tiktoken_enable":null,"tiktoken_model_name":null},"description":"Generate embeddings using OpenAI models.","display_name":"OpenAI Embeddings","documentation":"","field_formatters":{},"field_order":[],"frozen":false,"output_types":["Embeddings"],"template":{"_type":"CustomComponent","allowed_special":{"advanced":true,"display_name":"Allowed Special","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"allowed_special","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":[]},"chunk_size":{"advanced":true,"display_name":"Chunk Size","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"chunk_size","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Dict, List, Optional\n\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, NestedDict\n\n\nclass OpenAIEmbeddingsComponent(CustomComponent):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n\n    def build_config(self):\n        return {\n            \"allowed_special\": {\n                \"display_name\": \"Allowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"default_headers\": {\n                \"display_name\": \"Default Headers\",\n                \"advanced\": True,\n                \"field_type\": \"dict\",\n            },\n            \"default_query\": {\n                \"display_name\": \"Default Query\",\n                \"advanced\": True,\n                \"field_type\": \"NestedDict\",\n            },\n            \"disallowed_special\": {\n                \"display_name\": \"Disallowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"advanced\": True},\n            \"client\": {\"display_name\": \"Client\", \"advanced\": True},\n            \"deployment\": {\"display_name\": \"Deployment\", \"advanced\": True},\n            \"embedding_ctx_length\": {\n                \"display_name\": \"Embedding Context Length\",\n                \"advanced\": True,\n            },\n            \"max_retries\": {\"display_name\": \"Max Retries\", \"advanced\": True},\n            \"model\": {\n                \"display_name\": \"Model\",\n                \"advanced\": False,\n                \"options\": [\n                    \"text-embedding-3-small\",\n                    \"text-embedding-3-large\",\n                    \"text-embedding-ada-002\",\n                ],\n            },\n            \"model_kwargs\": {\"display_name\": \"Model Kwargs\", \"advanced\": True},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"password\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\"display_name\": \"OpenAI API Key\", \"password\": True},\n            \"openai_api_type\": {\n                \"display_name\": \"OpenAI API Type\",\n                \"advanced\": True,\n                \"password\": True,\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"advanced\": True,\n            },\n            \"openai_organization\": {\n                \"display_name\": \"OpenAI Organization\",\n                \"advanced\": True,\n            },\n            \"openai_proxy\": {\"display_name\": \"OpenAI Proxy\", \"advanced\": True},\n            \"request_timeout\": {\"display_name\": \"Request Timeout\", \"advanced\": True},\n            \"show_progress_bar\": {\n                \"display_name\": \"Show Progress Bar\",\n                \"advanced\": True,\n            },\n            \"skip_empty\": {\"display_name\": \"Skip Empty\", \"advanced\": True},\n            \"tiktoken_model_name\": {\n                \"display_name\": \"TikToken Model Name\",\n                \"advanced\": True,\n            },\n            \"tiktoken_enable\": {\"display_name\": \"TikToken Enable\", \"advanced\": True},\n        }\n\n    def build(\n        self,\n        openai_api_key: str,\n        default_headers: Optional[Dict[str, str]] = None,\n        default_query: Optional[NestedDict] = {},\n        allowed_special: List[str] = [],\n        disallowed_special: List[str] = [\"all\"],\n        chunk_size: int = 1000,\n        deployment: str = \"text-embedding-ada-002\",\n        embedding_ctx_length: int = 8191,\n        max_retries: int = 6,\n        model: str = \"text-embedding-ada-002\",\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        openai_api_type: Optional[str] = None,\n        openai_api_version: Optional[str] = None,\n        openai_organization: Optional[str] = None,\n        openai_proxy: Optional[str] = None,\n        request_timeout: Optional[float] = None,\n        show_progress_bar: bool = False,\n        skip_empty: bool = False,\n        tiktoken_enable: bool = True,\n        tiktoken_model_name: Optional[str] = None,\n    ) -> Embeddings:\n        # This is to avoid errors with Vector Stores (e.g Chroma)\n        if disallowed_special == [\"all\"]:\n            disallowed_special = \"all\"  # type: ignore\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        return OpenAIEmbeddings(\n            tiktoken_enabled=tiktoken_enable,\n            default_headers=default_headers,\n            default_query=default_query,\n            allowed_special=set(allowed_special),\n            disallowed_special=\"all\",\n            chunk_size=chunk_size,\n            deployment=deployment,\n            embedding_ctx_length=embedding_ctx_length,\n            max_retries=max_retries,\n            model=model,\n            model_kwargs=model_kwargs,\n            base_url=openai_api_base,\n            api_key=api_key,\n            openai_api_type=openai_api_type,\n            api_version=openai_api_version,\n            organization=openai_organization,\n            openai_proxy=openai_proxy,\n            timeout=request_timeout,\n            show_progress_bar=show_progress_bar,\n            skip_empty=skip_empty,\n            tiktoken_model_name=tiktoken_model_name,\n        )\n"},"default_headers":{"advanced":true,"display_name":"Default Headers","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"default_headers","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"dict"},"default_query":{"advanced":true,"display_name":"Default Query","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"default_query","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"deployment":{"advanced":true,"display_name":"Deployment","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"deployment","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"text-embedding-ada-002"},"disallowed_special":{"advanced":true,"display_name":"Disallowed Special","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"disallowed_special","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":["all"]},"embedding_ctx_length":{"advanced":true,"display_name":"Embedding Context Length","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"embedding_ctx_length","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":8191},"max_retries":{"advanced":true,"display_name":"Max Retries","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"max_retries","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"int","value":6},"model":{"advanced":false,"display_name":"Model","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":true,"load_from_db":false,"multiline":false,"name":"model","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"text-embedding-ada-002"},"model_kwargs":{"advanced":true,"display_name":"Model Kwargs","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"model_kwargs","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"NestedDict","value":{}},"openai_api_base":{"advanced":true,"display_name":"OpenAI API Base","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_base","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"openai_api_key":{"advanced":false,"display_name":"OpenAI API Key","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":true,"multiline":false,"name":"openai_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"openai_api_type":{"advanced":true,"display_name":"OpenAI API Type","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_type","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"openai_api_version":{"advanced":true,"display_name":"OpenAI API Version","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_api_version","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_organization":{"advanced":true,"display_name":"OpenAI Organization","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_organization","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"openai_proxy":{"advanced":true,"display_name":"OpenAI Proxy","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"openai_proxy","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"},"request_timeout":{"advanced":true,"display_name":"Request Timeout","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"request_timeout","password":false,"placeholder":"","rangeSpec":{"max":1,"min":-1,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"type":"float"},"show_progress_bar":{"advanced":true,"display_name":"Show Progress Bar","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"show_progress_bar","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"skip_empty":{"advanced":true,"display_name":"Skip Empty","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"skip_empty","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":false},"tiktoken_enable":{"advanced":true,"display_name":"TikToken Enable","dynamic":false,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":false,"name":"tiktoken_enable","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"bool","value":true},"tiktoken_model_name":{"advanced":true,"display_name":"TikToken Model Name","dynamic":false,"fileTypes":[],"file_path":"","info":"","input_types":["Text"],"list":false,"load_from_db":false,"multiline":false,"name":"tiktoken_model_name","password":false,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str"}}},"type":"OpenAIEmbeddings"},"selected":false,"width":384,"height":383,"positionAbsolute":{"x":3890.5630088192665,"y":2243.5231275702927},"dragging":false},{"id":"Chroma-11w57","type":"genericNode","position":{"x":2121.188458583652,"y":810.2548600907971},"data":{"type":"Chroma","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"inputs":{"type":"Record","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"allow_duplicates":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"allow_duplicates","display_name":"Allow Duplicates","advanced":true,"dynamic":false,"info":"If false, will not add documents that are already in the Vector Store.","load_from_db":false,"title_case":false},"chroma_server_cors_allow_origins":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[],"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_cors_allow_origins","display_name":"Server CORS Allow Origins","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_grpc_port":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_grpc_port","display_name":"Server gRPC Port","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chroma_server_host":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_host","display_name":"Server Host","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_http_port":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_http_port","display_name":"Server HTTP Port","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chroma_server_ssl_enabled":{"type":"bool","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_ssl_enabled","display_name":"Server SSL Enabled","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from copy import deepcopy\nfrom typing import List, Optional, Union\n\nimport chromadb\nfrom chromadb.config import Settings\nfrom langchain_chroma import Chroma\nfrom langchain_core.embeddings import Embeddings\nfrom langchain_core.retrievers import BaseRetriever\nfrom langchain_core.vectorstores import VectorStore\n\nfrom langflow.base.vectorstores.utils import chroma_collection_to_records\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass ChromaComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing a Vector Store using Chroma.\n    \"\"\"\n\n    display_name: str = \"Chroma\"\n    description: str = \"Implementation of Vector Store using Chroma\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    icon = \"Chroma\"\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"collection_name\": {\"display_name\": \"Collection Name\", \"value\": \"langflow\"},\n            \"index_directory\": {\"display_name\": \"Persist Directory\"},\n            \"code\": {\"advanced\": True, \"display_name\": \"Code\"},\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"chroma_server_cors_allow_origins\": {\n                \"display_name\": \"Server CORS Allow Origins\",\n                \"advanced\": True,\n            },\n            \"chroma_server_host\": {\"display_name\": \"Server Host\", \"advanced\": True},\n            \"chroma_server_http_port\": {\"display_name\": \"Server HTTP Port\", \"advanced\": True},\n            \"chroma_server_grpc_port\": {\n                \"display_name\": \"Server gRPC Port\",\n                \"advanced\": True,\n            },\n            \"chroma_server_ssl_enabled\": {\n                \"display_name\": \"Server SSL Enabled\",\n                \"advanced\": True,\n            },\n            \"allow_duplicates\": {\n                \"display_name\": \"Allow Duplicates\",\n                \"advanced\": True,\n                \"info\": \"If false, will not add documents that are already in the Vector Store.\",\n            },\n        }\n\n    def build(\n        self,\n        collection_name: str,\n        embedding: Embeddings,\n        chroma_server_ssl_enabled: bool,\n        index_directory: Optional[str] = None,\n        inputs: Optional[List[Record]] = None,\n        chroma_server_cors_allow_origins: List[str] = [],\n        chroma_server_host: Optional[str] = None,\n        chroma_server_http_port: Optional[int] = None,\n        chroma_server_grpc_port: Optional[int] = None,\n        allow_duplicates: bool = False,\n    ) -> Union[VectorStore, BaseRetriever]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - collection_name (str): The name of the collection.\n        - embedding (Embeddings): The embeddings to use for the Vector Store.\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\n        - index_directory (Optional[str]): The directory to persist the Vector Store to.\n        - inputs (Optional[List[Record]]): The input records to use for the Vector Store.\n        - chroma_server_cors_allow_origins (List[str]): The CORS allow origins for the Chroma server.\n        - chroma_server_host (Optional[str]): The host for the Chroma server.\n        - chroma_server_http_port (Optional[int]): The HTTP port for the Chroma server.\n        - chroma_server_grpc_port (Optional[int]): The gRPC port for the Chroma server.\n        - allow_duplicates (bool): Whether to allow duplicates in the Vector Store.\n\n        Returns:\n        - Union[VectorStore, BaseRetriever]: The Vector Store or BaseRetriever object.\n        \"\"\"\n\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if chroma_server_host is not None:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins or [],\n                chroma_server_host=chroma_server_host,\n                chroma_server_http_port=chroma_server_http_port or None,\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\n            )\n            client = chromadb.HttpClient(settings=chroma_settings)\n\n        # If documents, then we need to create a Chroma instance using .from_documents\n\n        # Check index_directory and expand it if it is a relative path\n        if index_directory is not None:\n            index_directory = self.resolve_path(index_directory)\n\n        chroma = Chroma(\n            persist_directory=index_directory,\n            client=client,\n            embedding_function=embedding,\n            collection_name=collection_name,\n        )\n        if allow_duplicates:\n            stored_records = []\n        else:\n            stored_records = chroma_collection_to_records(chroma.get())\n            _stored_documents_without_id = []\n            for record in deepcopy(stored_records):\n                del record.id\n                _stored_documents_without_id.append(record)\n        documents = []\n        for _input in inputs or []:\n            if isinstance(_input, Record):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Inputs must be a Record objects.\")\n\n        if documents and embedding is not None:\n            # Filter documents\n\n            chroma.add_documents(documents)\n\n        self.status = stored_records\n        return chroma\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"nasa2","fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"index_directory":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"index_directory","display_name":"Persist Directory","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"nasa"},"_type":"CustomComponent"},"description":"Implementation of Vector Store using Chroma","icon":"Chroma","base_classes":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStore"],"display_name":"Chroma","documentation":"https://python.langchain.com/docs/integrations/vectorstores/chroma","custom_fields":{"collection_name":null,"embedding":null,"chroma_server_ssl_enabled":null,"index_directory":null,"inputs":null,"chroma_server_cors_allow_origins":null,"chroma_server_host":null,"chroma_server_http_port":null,"chroma_server_grpc_port":null,"allow_duplicates":null},"output_types":["VectorStore","BaseRetriever"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"Chroma-11w57","description":"Implementation of Vector Store using Chroma","display_name":"Chroma"},"selected":false,"width":384,"height":479,"positionAbsolute":{"x":2121.188458583652,"y":810.2548600907971},"dragging":false},{"id":"RecordsToText-PqOXg","type":"genericNode","position":{"x":6372.457406882709,"y":2047.0505147407366},"data":{"type":"RecordsToText","node":{"template":{"records":{"type":"Record","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"records","display_name":"Records","advanced":false,"dynamic":false,"info":"The records to convert to text.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\nfrom langflow.helpers.record import records_to_text\nfrom langflow.schema import Record\n\n\nclass RecordsToTextComponent(CustomComponent):\n    display_name = \"Records To Text\"\n    description = \"Convert Records into plain text following a specified template.\"\n\n    def build_config(self):\n        return {\n            \"records\": {\n                \"display_name\": \"Records\",\n                \"info\": \"The records to convert to text.\",\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"info\": \"The template to use for formatting the records. It can contain the keys {text}, {data} or any other key in the Record.\",\n            },\n        }\n\n    def build(\n        self,\n        records: list[Record],\n        template: str = \"Text: {text}\\nData: {data}\",\n    ) -> Text:\n        if not records:\n            return \"\"\n        if isinstance(records, Record):\n            records = [records]\n\n        result_string = records_to_text(template, records)\n        self.status = result_string\n        return result_string\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"{text}","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"The template to use for formatting the records. It can contain the keys {text}, {data} or any other key in the Record.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Convert Records into plain text following a specified template.","base_classes":["object","str","Text"],"display_name":"Records To Text","documentation":"","custom_fields":{"records":null,"template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"RecordsToText-PqOXg"},"selected":false,"width":384,"height":357,"positionAbsolute":{"x":6372.457406882709,"y":2047.0505147407366},"dragging":false},{"id":"Prompt-xE4x1","type":"genericNode","position":{"x":6907.937019156335,"y":2483.711363482681},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import TemplateField\nfrom langflow.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)\n        self.status = prompt.format_text()\n        return prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Answer the question based on the context.\n\n\nContext:\n{Context}\n\nUser query: {Query}\nAnswer:\n","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","Context":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"Context","display_name":"Context","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"Query":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"Query","display_name":"Query","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Prompt","Record"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["Context","Query"]},"output_types":["Prompt"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-xE4x1","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":477,"positionAbsolute":{"x":6907.937019156335,"y":2483.711363482681},"dragging":false},{"id":"OpenAIModel-GYJ3B","type":"genericNode","position":{"x":7430.425165500572,"y":2461.8046357172943},"data":{"type":"OpenAIModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"input_types":["Text","Record","Prompt"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import NestedDict, Text\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_value\": {\"display_name\": \"Input\", \"input_types\": [\"Text\", \"Record\", \"Prompt\"]},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        openai_api_key: str,\n        temperature: float = 0.1,\n        model_name: str = \"gpt-3.5-turbo\",\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":256,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-3.5-turbo","fileTypes":[],"file_path":"","password":false,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","load_from_db":true,"title_case":false,"input_types":["Text"],"value":""},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["object","str","Text"],"display_name":"OpenAI","documentation":"","custom_fields":{"input_value":null,"openai_api_key":null,"temperature":null,"model_name":null,"max_tokens":null,"model_kwargs":null,"openai_api_base":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["max_tokens","model_kwargs","model_name","openai_api_base","openai_api_key","temperature","input_value","system_message","stream"],"beta":false},"id":"OpenAIModel-GYJ3B"},"selected":false,"width":384,"height":563,"positionAbsolute":{"x":7430.425165500572,"y":2461.8046357172943},"dragging":false},{"id":"ChatOutput-F8MZS","type":"genericNode","position":{"x":8006.553146708598,"y":2730.6643602810395},"data":{"type":"ChatOutput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        files: Optional[list[str]] = None,\n    ) -> Message:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            files=files,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"files":null},"output_types":["Message"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-F8MZS"},"selected":false,"width":384,"height":383,"positionAbsolute":{"x":8006.553146708598,"y":2730.6643602810395},"dragging":false},{"id":"RecordsOutput-Clgk9","type":"genericNode","position":{"x":6376.933999863042,"y":1707.951246644608},"data":{"type":"RecordsOutput","node":{"template":{"input_value":{"type":"Record","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Records","advanced":false,"input_types":["Record"],"dynamic":false,"info":"Record or Record list to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass RecordOutput(CustomComponent):\n    display_name = \"Records Output\"\n    description = \"Display Records as a Table\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Records\",\n                \"input_types\": [\"Record\"],\n                \"info\": \"Record or Record list to be passed as input.\",\n            },\n        }\n\n    def build(self, input_value: Record) -> Record:\n        self.status = input_value\n        return input_value\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Display Records as a Table","base_classes":["Record"],"display_name":"Records Output","documentation":"","custom_fields":{"input_value":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"RecordsOutput-Clgk9","description":"Display Records as a Table","display_name":"Records Output"},"selected":false,"width":384,"height":243,"positionAbsolute":{"x":6376.933999863042,"y":1707.951246644608},"dragging":false},{"id":"TextOutput-wUYJW","type":"genericNode","position":{"x":7435.912098654938,"y":2085.949714643488},"data":{"type":"TextOutput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as output.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextOutput(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Text\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as output.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(self, input_value: Optional[Text] = \"\", record_template: Optional[str] = \"\") -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a text output in the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Text Output","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":false},"id":"TextOutput-wUYJW","description":"Display a text output in the Playground.","display_name":"Text Output"},"selected":false,"width":384,"height":289,"positionAbsolute":{"x":7435.912098654938,"y":2085.949714643488},"dragging":false},{"id":"SelfQueryRetriever-qSjKS","type":"genericNode","position":{"x":5865.61307148337,"y":1880.4297714033396},"data":{"type":"SelfQueryRetriever","node":{"template":{"attribute_infos":{"type":"Record","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"attribute_infos","display_name":"Metadata Field Info","advanced":false,"dynamic":false,"info":"Metadata Field Info to be passed as input.","load_from_db":false,"title_case":false},"document_content_description":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"document_content_description","display_name":"Document Content Description","advanced":false,"dynamic":false,"info":"Document Content Description to be passed as input.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"Teste"},"llm":{"type":"BaseLanguageModel","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"llm","display_name":"LLM","advanced":false,"dynamic":false,"info":"LLM to be passed as input.","load_from_db":false,"title_case":false},"query":{"type":"Message","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"query","display_name":"Query","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"Query to be passed as input.","load_from_db":false,"title_case":false},"vectorstore":{"type":"VectorStore","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"vectorstore","display_name":"Vector Store","advanced":false,"dynamic":false,"info":"Vector Store to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain_core.vectorstores import VectorStore\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseLanguageModel, Text\nfrom langflow.schema import Record\nfrom langflow.schema.message import Message\n\n\nclass SelfQueryRetrieverComponent(CustomComponent):\n    display_name: str = \"Self Query Retriever\"\n    description: str = \"Retriever that uses a vector store and an LLM to generate the vector store queries.\"\n    icon = \"LangChain\"\n\n    def build_config(self):\n        return {\n            \"query\": {\n                \"display_name\": \"Query\",\n                \"input_types\": [\"Message\", \"Text\"],\n                \"info\": \"Query to be passed as input.\",\n            },\n            \"vectorstore\": {\n                \"display_name\": \"Vector Store\",\n                \"info\": \"Vector Store to be passed as input.\",\n            },\n            \"attribute_infos\": {\n                \"display_name\": \"Metadata Field Info\",\n                \"info\": \"Metadata Field Info to be passed as input.\",\n            },\n            \"document_content_description\": {\n                \"display_name\": \"Document Content Description\",\n                \"info\": \"Document Content Description to be passed as input.\",\n            },\n            \"llm\": {\n                \"display_name\": \"LLM\",\n                \"info\": \"LLM to be passed as input.\",\n            },\n        }\n\n    def build(\n        self,\n        query: Message,\n        vectorstore: VectorStore,\n        attribute_infos: list[Record],\n        document_content_description: Text,\n        llm: BaseLanguageModel,\n    ) -> Record:\n        metadata_field_infos = [AttributeInfo(**record.data) for record in attribute_infos]\n        self_query_retriever = SelfQueryRetriever.from_llm(\n            llm=llm,\n            vectorstore=vectorstore,\n            document_contents=document_content_description,\n            metadata_field_info=metadata_field_infos,\n            enable_limit=True,\n        )\n\n        if isinstance(query, Message):\n            input_text = query.text\n        elif isinstance(query, str):\n            input_text = query\n        else:\n            raise ValueError(f\"Query type {type(query)} not supported.\")\n        documents = self_query_retriever.invoke(input=input_text)\n        records = [Record.from_document(document) for document in documents]\n        self.status = records\n        return records\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Retriever that uses a vector store and an LLM to generate the vector store queries.","icon":"LangChain","base_classes":["Record"],"display_name":"Self Query Retriever","documentation":"","custom_fields":{"query":null,"vectorstore":null,"attribute_infos":null,"document_content_description":null,"llm":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":false},"id":"SelfQueryRetriever-qSjKS","description":"Retriever that uses a vector store and an LLM to generate the vector store queries.","display_name":"Self Query Retriever"},"selected":false,"width":384,"height":501,"positionAbsolute":{"x":5865.61307148337,"y":1880.4297714033396},"dragging":false},{"id":"Chroma-ctNAE","type":"genericNode","position":{"x":4513.147038777186,"y":2336.5708346430674},"data":{"type":"Chroma","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"inputs":{"type":"Record","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"allow_duplicates":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"allow_duplicates","display_name":"Allow Duplicates","advanced":true,"dynamic":false,"info":"If false, will not add documents that are already in the Vector Store.","load_from_db":false,"title_case":false},"chroma_server_cors_allow_origins":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[],"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_cors_allow_origins","display_name":"Server CORS Allow Origins","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_grpc_port":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_grpc_port","display_name":"Server gRPC Port","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chroma_server_host":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_host","display_name":"Server Host","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chroma_server_http_port":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_http_port","display_name":"Server HTTP Port","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chroma_server_ssl_enabled":{"type":"bool","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"chroma_server_ssl_enabled","display_name":"Server SSL Enabled","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from copy import deepcopy\nfrom typing import List, Optional, Union\n\nimport chromadb\nfrom chromadb.config import Settings\nfrom langchain_chroma import Chroma\nfrom langchain_core.embeddings import Embeddings\nfrom langchain_core.retrievers import BaseRetriever\nfrom langchain_core.vectorstores import VectorStore\n\nfrom langflow.base.vectorstores.utils import chroma_collection_to_records\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass ChromaComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing a Vector Store using Chroma.\n    \"\"\"\n\n    display_name: str = \"Chroma\"\n    description: str = \"Implementation of Vector Store using Chroma\"\n    documentation = \"https://python.langchain.com/docs/integrations/vectorstores/chroma\"\n    icon = \"Chroma\"\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"collection_name\": {\"display_name\": \"Collection Name\", \"value\": \"langflow\"},\n            \"index_directory\": {\"display_name\": \"Persist Directory\"},\n            \"code\": {\"advanced\": True, \"display_name\": \"Code\"},\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"chroma_server_cors_allow_origins\": {\n                \"display_name\": \"Server CORS Allow Origins\",\n                \"advanced\": True,\n            },\n            \"chroma_server_host\": {\"display_name\": \"Server Host\", \"advanced\": True},\n            \"chroma_server_http_port\": {\"display_name\": \"Server HTTP Port\", \"advanced\": True},\n            \"chroma_server_grpc_port\": {\n                \"display_name\": \"Server gRPC Port\",\n                \"advanced\": True,\n            },\n            \"chroma_server_ssl_enabled\": {\n                \"display_name\": \"Server SSL Enabled\",\n                \"advanced\": True,\n            },\n            \"allow_duplicates\": {\n                \"display_name\": \"Allow Duplicates\",\n                \"advanced\": True,\n                \"info\": \"If false, will not add documents that are already in the Vector Store.\",\n            },\n        }\n\n    def build(\n        self,\n        collection_name: str,\n        embedding: Embeddings,\n        chroma_server_ssl_enabled: bool,\n        index_directory: Optional[str] = None,\n        inputs: Optional[List[Record]] = None,\n        chroma_server_cors_allow_origins: List[str] = [],\n        chroma_server_host: Optional[str] = None,\n        chroma_server_http_port: Optional[int] = None,\n        chroma_server_grpc_port: Optional[int] = None,\n        allow_duplicates: bool = False,\n    ) -> Union[VectorStore, BaseRetriever]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - collection_name (str): The name of the collection.\n        - embedding (Embeddings): The embeddings to use for the Vector Store.\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\n        - index_directory (Optional[str]): The directory to persist the Vector Store to.\n        - inputs (Optional[List[Record]]): The input records to use for the Vector Store.\n        - chroma_server_cors_allow_origins (List[str]): The CORS allow origins for the Chroma server.\n        - chroma_server_host (Optional[str]): The host for the Chroma server.\n        - chroma_server_http_port (Optional[int]): The HTTP port for the Chroma server.\n        - chroma_server_grpc_port (Optional[int]): The gRPC port for the Chroma server.\n        - allow_duplicates (bool): Whether to allow duplicates in the Vector Store.\n\n        Returns:\n        - Union[VectorStore, BaseRetriever]: The Vector Store or BaseRetriever object.\n        \"\"\"\n\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if chroma_server_host is not None:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins or [],\n                chroma_server_host=chroma_server_host,\n                chroma_server_http_port=chroma_server_http_port or None,\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\n            )\n            client = chromadb.HttpClient(settings=chroma_settings)\n\n        # Check index_directory and expand it if it is a relative path\n        if index_directory is not None:\n            index_directory = self.resolve_path(index_directory)\n\n        chroma = Chroma(\n            persist_directory=index_directory,\n            client=client,\n            embedding_function=embedding,\n            collection_name=collection_name,\n        )\n        if allow_duplicates:\n            stored_records = []\n        else:\n            stored_records = chroma_collection_to_records(chroma.get())\n            _stored_documents_without_id = []\n            for record in deepcopy(stored_records):\n                del record.id\n                _stored_documents_without_id.append(record)\n        documents = []\n        for _input in inputs or []:\n            if isinstance(_input, Record):\n                if _input not in _stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Inputs must be a Record objects.\")\n\n        if documents and embedding is not None:\n            chroma.add_documents(documents)\n\n        self.status = stored_records\n        return chroma\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"nasa2","fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"index_directory":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"index_directory","display_name":"Persist Directory","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"nasa"},"_type":"CustomComponent"},"description":"Implementation of Vector Store using Chroma","icon":"Chroma","base_classes":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStore"],"display_name":"Chroma","documentation":"https://python.langchain.com/docs/integrations/vectorstores/chroma","custom_fields":{"collection_name":null,"embedding":null,"chroma_server_ssl_enabled":null,"index_directory":null,"inputs":null,"chroma_server_cors_allow_origins":null,"chroma_server_host":null,"chroma_server_http_port":null,"chroma_server_grpc_port":null,"allow_duplicates":null},"output_types":["VectorStore","BaseRetriever"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"Chroma-ctNAE"},"selected":false,"width":384,"height":479,"positionAbsolute":{"x":4513.147038777186,"y":2336.5708346430674},"dragging":false}],"edges":[{"source":"OpenAIEmbeddings-oxAcv","sourceHandle":"{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-oxAcvœ}","target":"Chroma-11w57","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œChroma-11w57œ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","data":{"targetHandle":{"fieldName":"embedding","id":"Chroma-11w57","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-oxAcv"}},"id":"reactflow__edge-OpenAIEmbeddings-oxAcv{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-oxAcvœ}-Chroma-11w57{œfieldNameœ:œembeddingœ,œidœ:œChroma-11w57œ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","className":""},{"source":"File-wx5iL","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-wx5iLœ}","target":"Chroma-11w57","targetHandle":"{œfieldNameœ:œinputsœ,œidœ:œChroma-11w57œ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"inputs","id":"Chroma-11w57","inputTypes":["Document","Record"],"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"File","id":"File-wx5iL"}},"id":"reactflow__edge-File-wx5iL{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-wx5iLœ}-Chroma-11w57{œfieldNameœ:œinputsœ,œidœ:œChroma-11w57œ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œRecordœ}","className":""},{"source":"RecordsToText-PqOXg","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œRecordsToTextœ,œidœ:œRecordsToText-PqOXgœ}","target":"Prompt-xE4x1","targetHandle":"{œfieldNameœ:œContextœ,œidœ:œPrompt-xE4x1œ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Context","id":"Prompt-xE4x1","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"RecordsToText","id":"RecordsToText-PqOXg"}},"id":"reactflow__edge-RecordsToText-PqOXg{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œRecordsToTextœ,œidœ:œRecordsToText-PqOXgœ}-Prompt-xE4x1{œfieldNameœ:œContextœ,œidœ:œPrompt-xE4x1œ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-xE4x1","sourceHandle":"{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-xE4x1œ}","target":"OpenAIModel-GYJ3B","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-GYJ3Bœ,œinputTypesœ:[œTextœ,œRecordœ,œPromptœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-GYJ3B","inputTypes":["Text","Record","Prompt"],"type":"str"},"sourceHandle":{"baseClasses":["Prompt","Record"],"dataType":"Prompt","id":"Prompt-xE4x1"}},"id":"reactflow__edge-Prompt-xE4x1{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-xE4x1œ}-OpenAIModel-GYJ3B{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-GYJ3Bœ,œinputTypesœ:[œTextœ,œRecordœ,œPromptœ],œtypeœ:œstrœ}","className":""},{"source":"OpenAIModel-GYJ3B","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-GYJ3Bœ}","target":"ChatOutput-F8MZS","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-F8MZSœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-F8MZS","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"OpenAIModel","id":"OpenAIModel-GYJ3B"}},"id":"reactflow__edge-OpenAIModel-GYJ3B{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-GYJ3Bœ}-ChatOutput-F8MZS{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-F8MZSœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-xE4x1","sourceHandle":"{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-xE4x1œ}","target":"TextOutput-wUYJW","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-wUYJWœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-wUYJW","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Prompt","Record"],"dataType":"Prompt","id":"Prompt-xE4x1"}},"id":"reactflow__edge-Prompt-xE4x1{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-xE4x1œ}-TextOutput-wUYJW{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-wUYJWœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"CustomComponent-U3ISA","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-U3ISAœ}","target":"SelfQueryRetriever-qSjKS","targetHandle":"{œfieldNameœ:œattribute_infosœ,œidœ:œSelfQueryRetriever-qSjKSœ,œinputTypesœ:null,œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"attribute_infos","id":"SelfQueryRetriever-qSjKS","inputTypes":null,"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"CustomComponent","id":"CustomComponent-U3ISA"}},"id":"reactflow__edge-CustomComponent-U3ISA{œbaseClassesœ:[œRecordœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-U3ISAœ}-SelfQueryRetriever-qSjKS{œfieldNameœ:œattribute_infosœ,œidœ:œSelfQueryRetriever-qSjKSœ,œinputTypesœ:null,œtypeœ:œRecordœ}"},{"source":"OpenAIEmbeddings-5EKft","sourceHandle":"{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-5EKftœ}","target":"Chroma-ctNAE","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œChroma-ctNAEœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","data":{"targetHandle":{"fieldName":"embedding","id":"Chroma-ctNAE","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-5EKft"}},"id":"reactflow__edge-OpenAIEmbeddings-5EKft{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-5EKftœ}-Chroma-ctNAE{œfieldNameœ:œembeddingœ,œidœ:œChroma-ctNAEœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}"},{"source":"Chroma-ctNAE","sourceHandle":"{œbaseClassesœ:[œBaseRetrieverœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ,œVectorStoreœ],œdataTypeœ:œChromaœ,œidœ:œChroma-ctNAEœ}","target":"SelfQueryRetriever-qSjKS","targetHandle":"{œfieldNameœ:œvectorstoreœ,œidœ:œSelfQueryRetriever-qSjKSœ,œinputTypesœ:null,œtypeœ:œVectorStoreœ}","data":{"targetHandle":{"fieldName":"vectorstore","id":"SelfQueryRetriever-qSjKS","inputTypes":null,"type":"VectorStore"},"sourceHandle":{"baseClasses":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStore"],"dataType":"Chroma","id":"Chroma-ctNAE"}},"id":"reactflow__edge-Chroma-ctNAE{œbaseClassesœ:[œBaseRetrieverœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ,œVectorStoreœ],œdataTypeœ:œChromaœ,œidœ:œChroma-ctNAEœ}-SelfQueryRetriever-qSjKS{œfieldNameœ:œvectorstoreœ,œidœ:œSelfQueryRetriever-qSjKSœ,œinputTypesœ:null,œtypeœ:œVectorStoreœ}"},{"source":"ChatOpenAISpecs-gQfib","sourceHandle":"{œbaseClassesœ:[œBaseLanguageModelœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œChatOpenAISpecsœ,œidœ:œChatOpenAISpecs-gQfibœ}","target":"SelfQueryRetriever-qSjKS","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œSelfQueryRetriever-qSjKSœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","data":{"targetHandle":{"fieldName":"llm","id":"SelfQueryRetriever-qSjKS","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"ChatOpenAISpecs","id":"ChatOpenAISpecs-gQfib"}},"id":"reactflow__edge-ChatOpenAISpecs-gQfib{œbaseClassesœ:[œBaseLanguageModelœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œChatOpenAISpecsœ,œidœ:œChatOpenAISpecs-gQfibœ}-SelfQueryRetriever-qSjKS{œfieldNameœ:œllmœ,œidœ:œSelfQueryRetriever-qSjKSœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"},{"source":"ChatInput-u9eMa","sourceHandle":"{œbaseClassesœ:[œMessageœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-u9eMaœ}","target":"SelfQueryRetriever-qSjKS","targetHandle":"{œfieldNameœ:œqueryœ,œidœ:œSelfQueryRetriever-qSjKSœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œMessageœ}","data":{"targetHandle":{"fieldName":"query","id":"SelfQueryRetriever-qSjKS","inputTypes":["Message","Text"],"type":"Message"},"sourceHandle":{"baseClasses":["Message"],"dataType":"ChatInput","id":"ChatInput-u9eMa"}},"id":"reactflow__edge-ChatInput-u9eMa{œbaseClassesœ:[œMessageœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-u9eMaœ}-SelfQueryRetriever-qSjKS{œfieldNameœ:œqueryœ,œidœ:œSelfQueryRetriever-qSjKSœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œMessageœ}"},{"source":"ChatInput-u9eMa","sourceHandle":"{œbaseClassesœ:[œMessageœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-u9eMaœ}","target":"Prompt-xE4x1","targetHandle":"{œfieldNameœ:œQueryœ,œidœ:œPrompt-xE4x1œ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"Query","id":"Prompt-xE4x1","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message"],"dataType":"ChatInput","id":"ChatInput-u9eMa"}},"id":"reactflow__edge-ChatInput-u9eMa{œbaseClassesœ:[œMessageœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-u9eMaœ}-Prompt-xE4x1{œfieldNameœ:œQueryœ,œidœ:œPrompt-xE4x1œ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"SelfQueryRetriever-qSjKS","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œSelfQueryRetrieverœ,œidœ:œSelfQueryRetriever-qSjKSœ}","target":"RecordsToText-PqOXg","targetHandle":"{œfieldNameœ:œrecordsœ,œidœ:œRecordsToText-PqOXgœ,œinputTypesœ:null,œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"records","id":"RecordsToText-PqOXg","inputTypes":null,"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"SelfQueryRetriever","id":"SelfQueryRetriever-qSjKS"}},"id":"reactflow__edge-SelfQueryRetriever-qSjKS{œbaseClassesœ:[œRecordœ],œdataTypeœ:œSelfQueryRetrieverœ,œidœ:œSelfQueryRetriever-qSjKSœ}-RecordsToText-PqOXg{œfieldNameœ:œrecordsœ,œidœ:œRecordsToText-PqOXgœ,œinputTypesœ:null,œtypeœ:œRecordœ}"},{"source":"SelfQueryRetriever-qSjKS","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œSelfQueryRetrieverœ,œidœ:œSelfQueryRetriever-qSjKSœ}","target":"RecordsOutput-Clgk9","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œRecordsOutput-Clgk9œ,œinputTypesœ:[œRecordœ],œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"input_value","id":"RecordsOutput-Clgk9","inputTypes":["Record"],"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"SelfQueryRetriever","id":"SelfQueryRetriever-qSjKS"}},"id":"reactflow__edge-SelfQueryRetriever-qSjKS{œbaseClassesœ:[œRecordœ],œdataTypeœ:œSelfQueryRetrieverœ,œidœ:œSelfQueryRetriever-qSjKSœ}-RecordsOutput-Clgk9{œfieldNameœ:œinput_valueœ,œidœ:œRecordsOutput-Clgk9œ,œinputTypesœ:[œRecordœ],œtypeœ:œRecordœ}"}],"viewport":{"x":-967.6916770355924,"y":-116.52865980310321,"zoom":0.265355802237463}},"description":"Innovation in Interaction with Langflow.","name":"Climate Prediction Updated","last_tested_version":"1.0.0a48","is_component":false}